{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://farm66.staticflickr.com/65535/49055715328_092031af74_o.png\"  width=\"150\" />\n",
    "\n",
    "### CBPF - Centro Brasileiro de Pesquisas Físicas\n",
    "\n",
    "# Projeto final do curso de Análise de big data e Astroinformática\n",
    "\n",
    "### João Paulo Correia de França\n",
    "### contato: joao.contato505@gmail.com\n",
    "\n",
    "\n",
    "### Professor: Clécio R. de Bom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tJulExpwKVFg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 14:49:07.480478: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-19 14:49:07.480553: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D,ZeroPadding2D,Activation\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Dropout,BatchNormalization,Flatten,Input\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9SDXzrmuQV7U"
   },
   "outputs": [],
   "source": [
    "path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7bhyvD_6Lf7L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current strong lensing systems on path: 22641\n"
     ]
    }
   ],
   "source": [
    "# images path\n",
    "\n",
    "files_names = os.listdir(path+'/LensPop/images/')\n",
    "\n",
    "print('Current strong lensing systems on path: {:4.0f}'.format(len(files_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "Lth-adp2OULb",
    "outputId": "44f787b8-b75c-4bde-f22a-32a325f3aa11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>zl</th>\n",
       "      <th>zs</th>\n",
       "      <th>b</th>\n",
       "      <th>sig_v</th>\n",
       "      <th>ql</th>\n",
       "      <th>rl</th>\n",
       "      <th>lens_g</th>\n",
       "      <th>lens_r</th>\n",
       "      <th>lens_i</th>\n",
       "      <th>...</th>\n",
       "      <th>rs</th>\n",
       "      <th>source_g</th>\n",
       "      <th>source_r</th>\n",
       "      <th>source_i</th>\n",
       "      <th>mu_s</th>\n",
       "      <th>g_band_coadd_seeing</th>\n",
       "      <th>g_band_coadd_signal_to_noise</th>\n",
       "      <th>r_band_coadd_seeing</th>\n",
       "      <th>r_band_coadd_signal_to_noise</th>\n",
       "      <th>i_band_coadd_seeing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.320</td>\n",
       "      <td>1.784</td>\n",
       "      <td>1.497</td>\n",
       "      <td>265.112</td>\n",
       "      <td>0.771</td>\n",
       "      <td>1.330</td>\n",
       "      <td>19.961</td>\n",
       "      <td>18.086</td>\n",
       "      <td>17.442</td>\n",
       "      <td>...</td>\n",
       "      <td>131.188</td>\n",
       "      <td>0.290</td>\n",
       "      <td>6.413</td>\n",
       "      <td>1.352</td>\n",
       "      <td>37.000</td>\n",
       "      <td>1.352</td>\n",
       "      <td>19.368</td>\n",
       "      <td>1.352</td>\n",
       "      <td>11.432</td>\n",
       "      <td>32.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.402</td>\n",
       "      <td>1.790</td>\n",
       "      <td>1.372</td>\n",
       "      <td>264.665</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.819</td>\n",
       "      <td>20.778</td>\n",
       "      <td>18.833</td>\n",
       "      <td>18.103</td>\n",
       "      <td>...</td>\n",
       "      <td>35.232</td>\n",
       "      <td>0.408</td>\n",
       "      <td>4.585</td>\n",
       "      <td>1.352</td>\n",
       "      <td>22.528</td>\n",
       "      <td>1.352</td>\n",
       "      <td>11.003</td>\n",
       "      <td>1.352</td>\n",
       "      <td>9.419</td>\n",
       "      <td>19.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.569</td>\n",
       "      <td>1.285</td>\n",
       "      <td>1.361</td>\n",
       "      <td>318.578</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.853</td>\n",
       "      <td>21.374</td>\n",
       "      <td>19.530</td>\n",
       "      <td>18.255</td>\n",
       "      <td>...</td>\n",
       "      <td>113.910</td>\n",
       "      <td>0.290</td>\n",
       "      <td>8.931</td>\n",
       "      <td>1.352</td>\n",
       "      <td>32.892</td>\n",
       "      <td>1.352</td>\n",
       "      <td>22.761</td>\n",
       "      <td>1.352</td>\n",
       "      <td>16.575</td>\n",
       "      <td>28.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.189</td>\n",
       "      <td>3.385</td>\n",
       "      <td>1.686</td>\n",
       "      <td>257.082</td>\n",
       "      <td>0.709</td>\n",
       "      <td>2.291</td>\n",
       "      <td>18.166</td>\n",
       "      <td>16.757</td>\n",
       "      <td>16.249</td>\n",
       "      <td>...</td>\n",
       "      <td>125.445</td>\n",
       "      <td>0.321</td>\n",
       "      <td>7.212</td>\n",
       "      <td>1.352</td>\n",
       "      <td>23.054</td>\n",
       "      <td>1.352</td>\n",
       "      <td>15.983</td>\n",
       "      <td>1.352</td>\n",
       "      <td>9.900</td>\n",
       "      <td>17.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.057</td>\n",
       "      <td>0.658</td>\n",
       "      <td>242.661</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.409</td>\n",
       "      <td>22.679</td>\n",
       "      <td>20.836</td>\n",
       "      <td>19.562</td>\n",
       "      <td>...</td>\n",
       "      <td>53.932</td>\n",
       "      <td>0.008</td>\n",
       "      <td>156.589</td>\n",
       "      <td>1.352</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.352</td>\n",
       "      <td>21.890</td>\n",
       "      <td>1.352</td>\n",
       "      <td>25.334</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     zl     zs      b    sig_v     ql     rl  lens_g  lens_r  lens_i  \\\n",
       "0   0  0.320  1.784  1.497  265.112  0.771  1.330  19.961  18.086  17.442   \n",
       "1   1  0.402  1.790  1.372  264.665  0.811  0.819  20.778  18.833  18.103   \n",
       "2   3  0.569  1.285  1.361  318.578  0.671  0.853  21.374  19.530  18.255   \n",
       "3   4  0.189  3.385  1.686  257.082  0.709  2.291  18.166  16.757  16.249   \n",
       "4   5  0.568  1.057  0.658  242.661  0.768  0.409  22.679  20.836  19.562   \n",
       "\n",
       "   ...       rs  source_g  source_r  source_i    mu_s  g_band_coadd_seeing  \\\n",
       "0  ...  131.188     0.290     6.413     1.352  37.000                1.352   \n",
       "1  ...   35.232     0.408     4.585     1.352  22.528                1.352   \n",
       "2  ...  113.910     0.290     8.931     1.352  32.892                1.352   \n",
       "3  ...  125.445     0.321     7.212     1.352  23.054                1.352   \n",
       "4  ...   53.932     0.008   156.589     1.352   0.002                1.352   \n",
       "\n",
       "   g_band_coadd_signal_to_noise  r_band_coadd_seeing  \\\n",
       "0                        19.368                1.352   \n",
       "1                        11.003                1.352   \n",
       "2                        22.761                1.352   \n",
       "3                        15.983                1.352   \n",
       "4                        21.890                1.352   \n",
       "\n",
       "   r_band_coadd_signal_to_noise  i_band_coadd_seeing  \n",
       "0                        11.432               32.021  \n",
       "1                         9.419               19.750  \n",
       "2                        16.575               28.284  \n",
       "3                         9.900               17.660  \n",
       "4                        25.334                0.000  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Catalog simulation parameters (true values)\n",
    "lenses_DESc = pd.read_csv(path+'/lenses_DESc.txt',\n",
    "                          sep=' ',\n",
    "                          comment='#',\n",
    "                          names=['id', 'zl', 'zs', 'b', 'sig_v', 'ql', 'rl', 'lens_g', 'lens_r', 'lens_i', 'xs', 'ys', 'qs', 'ps', 'rs', 'source_g', 'source_r', 'source_i', 'mu_s', 'g_band_coadd_seeing', 'g_band_coadd_signal_to_noise', 'r_band_coadd_seeing', 'r_band_coadd_signal_to_noise', 'i_band_coadd_seeing'])\n",
    "lenses_DESc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BJe8aTFZOu6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong lensing systems (after cut) on path: 18598\n"
     ]
    }
   ],
   "source": [
    "# not all images have information in lenses_DESc.txt. In order to avoid some trouble, lets perform a cut on data\n",
    "data_cut = []\n",
    "for i in range(0, len(files_names)):\n",
    "    if int(files_names[i]) in np.array(lenses_DESc['id']):\n",
    "        #if len(data_cut) < 500:\n",
    "        data_cut.append(int(files_names[i]))\n",
    "        \n",
    "print('Strong lensing systems (after cut) on path: {:4.0f}'.format(len(data_cut)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxv8m3L3NpEw",
    "outputId": "7bba8ed8-4551-42fc-b272-0062ac5d0112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14878 3720\n"
     ]
    }
   ],
   "source": [
    "# split our data in training and test dataset with ration 80 - 20 %\n",
    "np.random.seed(42)\n",
    "files_names_train, files_names_test = train_test_split(data_cut, test_size=0.2)\n",
    "print(len(files_names_train), len(files_names_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jzv5mwUONsME",
    "outputId": "975a9275-3fba-4fa3-c005-d4281c978de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13390 3720 1488\n"
     ]
    }
   ],
   "source": [
    "# split our data in training and validation dataset with ration 90 - 10 %\n",
    "np.random.seed(42)\n",
    "files_names_train, files_names_val = train_test_split(files_names_train, test_size=0.1)\n",
    "print(len(files_names_train), len(files_names_test), len(files_names_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_systems=os.listdir(path+'/output/')\n",
    "\n",
    "bayesian_systems = np.array(bayesian_systems, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13370 3742 1486\n"
     ]
    }
   ],
   "source": [
    "# removing bayesian systems in train and validation data set and adding in the test dataset\n",
    "idx_train = []\n",
    "idx_val = []\n",
    "for i in range(0, len(bayesian_systems)):\n",
    "    if bayesian_systems[i] in files_names_train:\n",
    "        idx_train.append(np.where(files_names_train==bayesian_systems[i])[0][0])\n",
    "    if bayesian_systems[i] in files_names_val:\n",
    "        idx_val.append(np.where(files_names_val==bayesian_systems[i])[0][0])\n",
    "    if bayesian_systems[i] not in files_names_test:\n",
    "        files_names_test.append(bayesian_systems[i])\n",
    "    \n",
    "files_names_train=np.delete(files_names_train, idx_train)\n",
    "files_names_val=np.delete(files_names_val, idx_val)\n",
    "\n",
    "# result\n",
    "print(len(files_names_train), len(files_names_test), len(files_names_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qite3lgTNuO2",
    "outputId": "64df9edf-c5c3-428e-eee0-b64560728d93",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(0, len(files_names_train)):\n",
    "    #print(i)\n",
    "    x_train.append(np.array([fits.open(path+'/LensPop/images/'+str(files_names_train[i])+\"/image_g_SDSS.fits\")[0].data, fits.open(path+'/LensPop/images/'+str(files_names_train[i])+\"/image_r_SDSS.fits\")[0].data, fits.open(path+'/LensPop/images/'+str(files_names_train[i])+\"/image_i_SDSS.fits\")[0].data]))\n",
    "    y_train.append(float(lenses_DESc[\"b\"][lenses_DESc[\"id\"]==files_names_train[i]]))\n",
    "\n",
    "# test\n",
    "x_test = []\n",
    "y_test = [] # true values\n",
    "for i in range(0, len(files_names_test)):\n",
    "    #print(i)\n",
    "    x_test.append(np.array([fits.open(path+'/LensPop/images/'+str(files_names_test[i])+\"/image_g_SDSS.fits\")[0].data, fits.open(path+'/LensPop/images/'+str(files_names_test[i])+\"/image_r_SDSS.fits\")[0].data, fits.open(path+'/LensPop/images/'+str(files_names_test[i])+\"/image_i_SDSS.fits\")[0].data]))\n",
    "    y_test.append(float(lenses_DESc[\"b\"][lenses_DESc[\"id\"]==files_names_test[i]]))\n",
    "\n",
    "# val\n",
    "x_val = []\n",
    "y_val = [] \n",
    "for i in range(0, len(files_names_val)):\n",
    "    #print(i)\n",
    "    x_val.append(np.array([fits.open(path+'/LensPop/images/'+str(files_names_val[i])+\"/image_g_SDSS.fits\")[0].data, fits.open(path+'/LensPop/images/'+str(files_names_val[i])+\"/image_r_SDSS.fits\")[0].data, fits.open(path+'/LensPop/images/'+str(files_names_val[i])+\"/image_i_SDSS.fits\")[0].data]))\n",
    "    y_val.append(float(lenses_DESc[\"b\"][lenses_DESc[\"id\"]==files_names_val[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Iase6XKmR7b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13370, 76, 76, 3) (3742, 76, 76, 3) (1486, 76, 76, 3)\n"
     ]
    }
   ],
   "source": [
    "# transform into arrays and move some axis\n",
    "x_train = np.array(x_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "\n",
    "x_test = np.array(x_test, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "x_val = np.array(x_val, dtype=np.float32)\n",
    "y_val = np.array(y_val, dtype=np.float32)\n",
    "\n",
    "x_train = np.moveaxis(x_train, 1, 2)\n",
    "x_train = np.moveaxis(x_train, 3, 2)\n",
    "\n",
    "x_test = np.moveaxis(x_test, 1, 2)\n",
    "x_test = np.moveaxis(x_test, 3, 2)\n",
    "\n",
    "x_val = np.moveaxis(x_val, 1, 2)\n",
    "x_val = np.moveaxis(x_val, 3, 2)\n",
    "\n",
    "print(x_train.shape, x_test.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 14:57:09.276740: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-19 14:57:09.282330: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-19 14:57:09.283601: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-0SVSQGR): /proc/driver/nvidia/version does not exist\n",
      "2021-11-19 14:57:09.295982: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/tmp/ipykernel_6721/1136489678.py:35: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/417 [..............................] - ETA: 15:19 - loss: 131.6888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 14:57:12.586747: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29859840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/417 [..............................] - ETA: 1:18 - loss: 428.9514 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 14:57:12.792588: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29859840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/417 [..............................] - ETA: 1:23 - loss: 292.0796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 14:57:12.999735: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29859840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  4/417 [..............................] - ETA: 1:29 - loss: 220.5221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 14:57:13.240513: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29859840 exceeds 10% of free system memory.\n",
      "2021-11-19 14:57:13.415284: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29859840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 70s 163ms/step - loss: 3.0371 - val_loss: 0.1022\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 65s 155ms/step - loss: 0.0903 - val_loss: 0.0838\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 62s 148ms/step - loss: 0.0950 - val_loss: 0.0620\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 61s 145ms/step - loss: 0.0606 - val_loss: 0.0540\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 63s 152ms/step - loss: 0.0503 - val_loss: 0.0441\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 63s 151ms/step - loss: 0.0549 - val_loss: 0.1752\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 65s 155ms/step - loss: 0.0489 - val_loss: 0.0455\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 63s 151ms/step - loss: 0.0449 - val_loss: 0.0510\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 60s 144ms/step - loss: 0.0626 - val_loss: 0.0463\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 61s 146ms/step - loss: 0.0459 - val_loss: 0.0403\n",
      "Epoch 11/20\n",
      "417/417 [==============================] - 61s 147ms/step - loss: 0.0397 - val_loss: 0.0369\n",
      "Epoch 12/20\n",
      "417/417 [==============================] - 65s 156ms/step - loss: 0.0422 - val_loss: 0.0556\n",
      "Epoch 13/20\n",
      "417/417 [==============================] - 64s 153ms/step - loss: 0.0379 - val_loss: 0.0351\n",
      "Epoch 14/20\n",
      "417/417 [==============================] - 63s 152ms/step - loss: 0.0372 - val_loss: 0.0402\n",
      "Epoch 15/20\n",
      "417/417 [==============================] - 64s 154ms/step - loss: 0.0331 - val_loss: 0.0304\n",
      "Epoch 16/20\n",
      "417/417 [==============================] - 63s 150ms/step - loss: 0.0381 - val_loss: 0.0390\n",
      "Epoch 17/20\n",
      "417/417 [==============================] - 62s 149ms/step - loss: 0.0340 - val_loss: 0.0305\n",
      "Epoch 18/20\n",
      "417/417 [==============================] - 63s 150ms/step - loss: 0.0319 - val_loss: 0.0324\n",
      "Epoch 19/20\n",
      "417/417 [==============================] - 62s 148ms/step - loss: 0.0310 - val_loss: 0.0305\n",
      "Epoch 20/20\n",
      "417/417 [==============================] - 64s 154ms/step - loss: 0.0313 - val_loss: 0.0338\n"
     ]
    }
   ],
   "source": [
    "# Our deep learning algorithm \n",
    "inputs = tf.keras.Input(shape=(76, 76, 3))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(1,1), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(1,1), activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu')(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "#x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "#x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'mse'\n",
    ")\n",
    "\n",
    "gen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "batch_size=32\n",
    "start = time.perf_counter()\n",
    "generator = gen.flow(x_train, y_train, batch_size = batch_size)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator,\n",
    "    steps_per_epoch=len(x_train)/batch_size,\n",
    "    epochs=20,\n",
    "    validation_data = (x_val, y_val),\n",
    "    validation_steps = len(x_val),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wLLe3JkWdwwA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({\"font.size\": 13})\n",
    "\n",
    "plt.plot(history.history['loss'], label='train', c='slateblue')\n",
    "plt.plot(history.history['val_loss'], label='validation', c='salmon')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.17399058625945210132535123648267472162842750549316\n",
      "Test R^2: 0.83100647527476678710911528469296172261238098144531\n"
     ]
    }
   ],
   "source": [
    "predicted_radius = np.squeeze(model.predict(x_test))\n",
    "true_radius = y_test\n",
    "\n",
    "rmse = np.sqrt(model.evaluate(x_test, y_test, verbose=0))\n",
    "print('Test RMSE: {:.50f}'.format(rmse))\n",
    "\n",
    "r2 = r2_score(true_radius, predicted_radius)\n",
    "print('Test R^2: {:.50f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sys</th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3111.0</td>\n",
       "      <td>1.812359</td>\n",
       "      <td>1.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6113.0</td>\n",
       "      <td>1.399884</td>\n",
       "      <td>1.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>1.442858</td>\n",
       "      <td>1.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14954.0</td>\n",
       "      <td>1.882448</td>\n",
       "      <td>1.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19867.0</td>\n",
       "      <td>0.823879</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sys      pred   true\n",
       "0   3111.0  1.812359  1.497\n",
       "1   6113.0  1.399884  1.442\n",
       "2  16001.0  1.442858  1.541\n",
       "3  14954.0  1.882448  1.819\n",
       "4  19867.0  0.823879  0.806"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(np.array([files_names_test, predicted_radius, true_radius]).T, columns=['sys', 'pred', 'true'])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./DL_results.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deep_learning_lens.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
